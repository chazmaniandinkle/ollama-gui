# Ollama GUI

A user-friendly interface for interacting with local and remote Large Language Models (LLMs).

## Features

- Chat with local LLMs via Ollama
- Multi-provider support (Ollama, OpenAI, Anthropic)
- Conversation management with tagging and search
- Document upload and RAG capabilities
- WebSocket-based response streaming
- Mobile-friendly responsive design

## Getting Started

### Prerequisites

- Python 3.10+
- Node.js 18+
- Ollama (for local LLM support)

### Installation

1. Clone the repository
2. Set up the backend (see backend/README.md)
3. Set up the frontend (see frontend/README.md)

## Development

See [CONTRIBUTING.md](./CONTRIBUTING.md) for development guidelines.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
